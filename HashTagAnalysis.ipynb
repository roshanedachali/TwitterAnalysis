{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HashTagAnalysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNO9AI/9I4F1jUng9Fy829P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshanedachali/TwitterAnalysis/blob/main/HashTagAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRV7UItieSqd"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDsMVnIMYPys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d70df05-9fa5-46f0-eb21-a1deca9f8a27"
      },
      "source": [
        "#IMPORT\n",
        "import tweepy\n",
        "import csv\n",
        "! pip install jsonpickle\n",
        "import jsonpickle\n",
        "API_KEY=\"Q76360NUPSaax6Ic1MyPCqPhD\"\n",
        "API_SECRET=\"Ef5NJGN1GVJ6hwjOgh7Tv5NtOrBgipvE2umyrP37qkh8XWbOmC\"\n",
        "ACCESS_TOKEN=\"3180237764-o2OUouxEnigruw79ULQ2RrK78zbONdduBgScexi\"\n",
        "ACCESS_TOKEN_SECRET=\"yXCX26guHINaRHFCrlJmTTiSweTnlOTd67DDYdbJceQpl\"\n",
        "auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
        "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from jsonpickle) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAgmSrKNedRv"
      },
      "source": [
        "# Get and Store Tweets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNlU_ewxa8oQ",
        "outputId": "4c559893-7e56-468c-b8c8-5eddedcc6ba4"
      },
      "source": [
        "tweetsPerQuery = 100 #this is the maximum provided by API\n",
        "max_tweets = 100000000 # just for the sake of While loop\n",
        "\n",
        "# No sinceId and max_id ..Get whathever you have exhaustively\n",
        "since_id = None\n",
        "max_id = -1\n",
        "tweet_count = 0\n",
        "\n",
        "search_query=\"#SwachhBharat\"\n",
        "x=0\n",
        "with open(\"sb_06_10_21.txt\",'w') as f:\n",
        "    print(\"Downloading hashtag: \" + search_query)\n",
        "    while(tweet_count<max_tweets):\n",
        "        try:\n",
        "            if(max_id<=0):\n",
        "                if(not since_id):\n",
        "                    new_tweets = api.search(q=search_query,count=tweetsPerQuery,lang=\"en\",tweet_mode='extended')\n",
        "\n",
        "                else:\n",
        "                    new_tweets = api.search(q=search_query,count=tweetsPerQuery,lang=\"en\",tweet_mode='extended',since_id=since_id)\n",
        "            else:\n",
        "                if(not since_id):\n",
        "                    new_tweets = api.search(q=search_query,count=tweetsPerQuery,lang=\"en\",tweet_mode='extended',max_id=str(max_id-1))\n",
        "                else:\n",
        "                    new_tweets = api.search(q=search_query,count=tweetsPerQuery,lang=\"en\",tweet_mode='extended',max_id=str(max_id-1),since_id=since_id)\n",
        "\n",
        "            # Tweets Exhausted\n",
        "            if(not new_tweets):\n",
        "                break\n",
        "            # write all the new_tweets to a json file\n",
        "            for tweet in new_tweets:\n",
        "                f.write(jsonpickle.encode(tweet._json,unpicklable=False)+'\\n')\n",
        "                tweet_count+=len(new_tweets)\n",
        "                max_id=new_tweets[-1].id\n",
        "        # in case of any error\n",
        "        except tweepy.TweepError as e:\n",
        "                print(\"Some error!!:\"+str(e))\n",
        "                break\n",
        "\n",
        "print(\"A total of {0} tweets were downloaded and saved.\".format(tweet_count))\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading hashtag: #SwachhBharat\n",
            "A total of 234935 tweets were downloaded and saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BNMiIDx9-0w"
      },
      "source": [
        "# Editing the CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "7eQZlWjOgX1F",
        "outputId": "107e6cd6-6ff9-4bf7-f96c-fdd6f8b29248"
      },
      "source": [
        "import json\n",
        "import csv\n",
        "import io\n",
        "\n",
        "\n",
        "\n",
        "f = open('som1.csv','a',encoding='utf-8')\n",
        "csvWriter = csv.writer(f)\n",
        "headers=['full_text','retweet_count','user_followers_count','favorite_count','place','coordinates','geo','created_at','id_str']\n",
        "csvWriter.writerow(headers)\n",
        "\n",
        "for inputFile in ['sb_10_06_21.txt']:#all the text-file names you want to convert to Csv in the sae folder as this code\n",
        "    tweets = []\n",
        "    for line in open(\"sb_06_10_21.txt\", 'r'):\n",
        "        tweets.append(json.loads(line))\n",
        "\n",
        "    print('HI',len(tweets))\n",
        "    count_lines=0\n",
        "    for tweet in tweets:\n",
        "        try:\n",
        "            csvWriter.writerow([tweet['full_text'],tweet['retweet_count'],tweet['user']['followers_count'],tweet['favorite_count'],tweet['place'],tweet['coordinates'],tweet['geo'],tweet['created_at'],str(tweet['id_str'])])\n",
        "            count_lines+=1\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "    print(count_lines)\n",
        "    \n",
        "import pandas as pd\n",
        "df = pd.read_csv('som1.csv', encoding = 'unicode_escape')\n",
        "df.head(5)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HI 2453\n",
            "2453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>place</th>\n",
              "      <th>coordinates</th>\n",
              "      <th>geo</th>\n",
              "      <th>created_at</th>\n",
              "      <th>id_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @WeMeanToClean: #WasteSegregation is the ke...</td>\n",
              "      <td>1</td>\n",
              "      <td>1163</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fri Jun 11 04:05:14 +0000 2021</td>\n",
              "      <td>1403201634381881351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#WasteSegregation is the key to effective #Was...</td>\n",
              "      <td>1</td>\n",
              "      <td>2198</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fri Jun 11 04:00:41 +0000 2021</td>\n",
              "      <td>1403200488741421058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @dpradhanbjp: India has transitioned from w...</td>\n",
              "      <td>228</td>\n",
              "      <td>126</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fri Jun 11 03:47:37 +0000 2021</td>\n",
              "      <td>1403197200318959617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @SwatiBhalla23: Plant a tree, plant a life!...</td>\n",
              "      <td>2</td>\n",
              "      <td>820</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fri Jun 11 03:46:31 +0000 2021</td>\n",
              "      <td>1403196922492600321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @ManishKhurana: Another one of our voluntee...</td>\n",
              "      <td>2</td>\n",
              "      <td>820</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fri Jun 11 03:46:21 +0000 2021</td>\n",
              "      <td>1403196883548450816</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           full_text  ...               id_str\n",
              "0  RT @WeMeanToClean: #WasteSegregation is the ke...  ...  1403201634381881351\n",
              "1  #WasteSegregation is the key to effective #Was...  ...  1403200488741421058\n",
              "2  RT @dpradhanbjp: India has transitioned from w...  ...  1403197200318959617\n",
              "3  RT @SwatiBhalla23: Plant a tree, plant a life!...  ...  1403196922492600321\n",
              "4  RT @ManishKhurana: Another one of our voluntee...  ...  1403196883548450816\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubHsWJ_9pxuu"
      },
      "source": [
        "# Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "O2PeQFk9puF6",
        "outputId": "bc49c444-ba2d-4e1b-b57f-e28b6bc5ca74"
      },
      "source": [
        "print(len(df.index))\n",
        "serlis=df.duplicated().tolist()\n",
        "print(serlis.count(True))\n",
        "serlis=df.duplicated(['full_text']).tolist()\n",
        "print(serlis.count(True))\n",
        "df=df.drop_duplicates(['full_text'])\n",
        "df.head(5)\n",
        "index = (df.index)\n",
        "import re\n",
        "i = 0\n",
        "j = 0\n",
        "while ((i+1) <= len(index)):\n",
        "    if (i == index[j]):\n",
        "      txt = df.loc[i][\"full_text\"]\n",
        "      txt=re.sub(r'@[A-Z0-9a-z_:]+','',txt)#replace username-tags\n",
        "      txt=re.sub(r'^[RT]+','',txt)#replace RT-tags\n",
        "      txt = re.sub('https?://[A-Za-z0-9./]+','',txt)#replace URLs\n",
        "      txt=re.sub(\"[^a-zA-Z]\", \" \",txt)#replace hashtags\n",
        "      df.at[i,\"full_text\"]=txt\n",
        "      i += 1\n",
        "      j += 1\n",
        "    else: \n",
        "      i += 1\n",
        "df = df.drop(\"id_str\", axis = 1)\n",
        "df.head()\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4886\n",
            "1833\n",
            "3998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>place</th>\n",
              "      <th>coordinates</th>\n",
              "      <th>geo</th>\n",
              "      <th>created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WasteSegregation is the key to effective  W...</td>\n",
              "      <td>1</td>\n",
              "      <td>1163</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fri Jun 11 04:05:14 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WasteSegregation is the key to effective  Was...</td>\n",
              "      <td>1</td>\n",
              "      <td>2198</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fri Jun 11 04:00:41 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>India has transitioned from women   s develo...</td>\n",
              "      <td>228</td>\n",
              "      <td>126</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fri Jun 11 03:47:37 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Plant a tree  plant a life     WeMeanToClean...</td>\n",
              "      <td>2</td>\n",
              "      <td>820</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fri Jun 11 03:46:31 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Another one of our volunteer sets up home nu...</td>\n",
              "      <td>2</td>\n",
              "      <td>820</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fri Jun 11 03:46:21 +0000 2021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           full_text  ...                      created_at\n",
              "0     WasteSegregation is the key to effective  W...  ...  Fri Jun 11 04:05:14 +0000 2021\n",
              "1   WasteSegregation is the key to effective  Was...  ...  Fri Jun 11 04:00:41 +0000 2021\n",
              "2    India has transitioned from women   s develo...  ...  Fri Jun 11 03:47:37 +0000 2021\n",
              "3    Plant a tree  plant a life     WeMeanToClean...  ...  Fri Jun 11 03:46:31 +0000 2021\n",
              "4    Another one of our volunteer sets up home nu...  ...  Fri Jun 11 03:46:21 +0000 2021\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le5bGqorTkBJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r311JwML_jFV"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "BXm2Vq4w_nkj",
        "outputId": "08f5c04d-3300-4a0b-9e9b-9b8b5df42f96"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer, PorterStemmer\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from textblob import TextBlob\n",
        "nltk.download('stopwords')\n",
        "senti_score = []\n",
        "df.head()\n",
        "\n",
        "## Change the reviews type to string\n",
        "df['full_text'] = df['full_text'].astype(str)\n",
        "\n",
        "## Before lowercasing \n",
        "df['full_text'][2]\n",
        "\n",
        "## Lowercase all reviews\n",
        "df['full_text'] = df['full_text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "\n",
        "## Remove special characters\n",
        "bad_chars = [';', ':', '!', \"*\", \"@\", \"$\", \"^\",\"&\",\"(\",\")\",\"?\",\"=\",\"/\",\"%\"] \n",
        "for i in bad_chars :\n",
        "    df = df.replace(i, '')\n",
        "\n",
        "## Remove stop words \n",
        "stop = stopwords.words('english')\n",
        "df['full_text'] = df['full_text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "\n",
        "## Stemming\n",
        "st = PorterStemmer()\n",
        "df['full_text'] = df['full_text'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "\n",
        "## Sentiment Analysis\n",
        "def senti(x):\n",
        "    return TextBlob(x).sentiment  \n",
        "\n",
        "df['senti_score'] = df['full_text'].apply(senti)\n",
        "\n",
        "#df.drop('geo', inplace=True, axis=1)\n",
        "\n",
        "df.head()\n",
        "#(Sentiment Score, Subjectivity Score)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>created_at</th>\n",
              "      <th>senti_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wastesegreg key effect wastemanag wemeantoclea...</td>\n",
              "      <td>Fri Jun 11 04:05:14 +0000 2021</td>\n",
              "      <td>(0.0, 1.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wastesegreg key effect wastemanag wemeantoclea...</td>\n",
              "      <td>Fri Jun 11 04:00:41 +0000 2021</td>\n",
              "      <td>(0.0, 1.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>india transit women develop women led develop ...</td>\n",
              "      <td>Fri Jun 11 03:47:37 +0000 2021</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>plant tree plant life wemeantoclean cleandelhi...</td>\n",
              "      <td>Fri Jun 11 03:46:31 +0000 2021</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>anoth one volunt set home nurseri nativetr gre...</td>\n",
              "      <td>Fri Jun 11 03:46:21 +0000 2021</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           full_text  ... senti_score\n",
              "0  wastesegreg key effect wastemanag wemeantoclea...  ...  (0.0, 1.0)\n",
              "1  wastesegreg key effect wastemanag wemeantoclea...  ...  (0.0, 1.0)\n",
              "2  india transit women develop women led develop ...  ...  (0.0, 0.0)\n",
              "3  plant tree plant life wemeantoclean cleandelhi...  ...  (0.0, 0.0)\n",
              "4  anoth one volunt set home nurseri nativetr gre...  ...  (0.0, 0.0)\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    }
  ]
}